{% set name = "alibi-detect" %}
{% set version = "0.8.1" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/alibi-detect-{{ version }}.tar.gz
  sha256: 329110ce128e68a940a35b93ebea086a3660964d88825e491f2319021e114035

build:
  number: 0
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv

requirements:
  host:
    - pip
    - python >=3.7
  run:
    - python >=3.7
    - dill >=0.3.0,<0.4.0
    - matplotlib-base >=3.0.0,<4.0.0
    - numba >=0.50.0,!=0.54.0,<0.56.0
    - numpy >=1.16.2,<2.0.0
    - opencv >=3.2.0,<5.0.0
    - pandas >=0.23.3,<2.0.0
    - pillow >=5.4.1,<9.0.0
    - requests >=2.21.0,<3.0.0
    - scikit-image >=0.14.2,!=0.17.1,<0.19
    - scikit-learn >=0.20.2,<1.1.0
    - scipy >=1.3.0,<2.0.0
    - tensorflow >=2.2.0,!=2.6.0,!=2.6.1,<2.8.0
    - tensorflow-probability >=0.8.0,<0.13.0
    - tqdm >=4.28.1,<5.0.0
    - transformers >=4.0.0,<5.0.0
    # Necessary for passing pip-check
    - absl-py >=0.10.0,<0.11.0
    - wrapt >=1.12.1,<1.13.0
    ## Note: Necessary for supporting "opencv"
    #  A. "mesa-libGL" should be present in "yum_requirements.txt".
    #  B. "libgdal" should be added to "meta.yaml:requirements:run".
    - libgdal

test:
  imports:
    - alibi_detect
  # commands:
  #   - pip check
  # requires:
  #   - pip

about:
  home: https://github.com/SeldonIO/alibi-detect
  summary: Algorithms for outlier detection, concept drift and metrics.
  license: Apache-2.0
  license_file: LICENSE
  description: |
    [Alibi Detect](https://github.com/SeldonIO/alibi-detect) is an open source 
    Python library focused on **outlier**, **adversarial** and **drift** detection. 
    The package aims to cover both online and offline detectors for tabular data, 
    text, images and time series. Both **TensorFlow** and **PyTorch** backends are 
    supported for drift detection.

    - [Documentation](https://docs.seldon.io/projects/alibi-detect/en/latest/)

    For more background on the importance of monitoring outliers and distributions 
    in a production setting, check out 
    [this talk](https://slideslive.com/38931758/monitoring-and-explainability-of-models-in-production?ref=speaker-37384-latest) 
    from the *Challenges in Deploying and Monitoring Machine Learning Systems* 
    ICML 2020 workshop, based on the paper [Monitoring and explainability of models 
    in production](https://arxiv.org/abs/2007.06299) and referencing Alibi Detect.

    For a thorough introduction to drift detection, check out [Protecting Your 
    Machine Learning Against Drift: An Introduction](https://youtu.be/tL5sEaQha5o). 
    he talk covers what drift is and why it pays to detect it, the different types 
    of drift, how it can be detected in a principled manner and also describes the 
    anatomy of a drift detector.


    PyPI: [https://pypi.org/project/alibi-detect/](https://pypi.org/project/alibi-detect/)

  doc_url: https://docs.seldon.io/projects/alibi-detect/en/latest/
  dev_url: https://github.com/SeldonIO/alibi-detect

extra:
  recipe-maintainers:
    - sugatoray
