{% set version = '0.1.4' %}

{% set posix = 'm2-' if win else '' %}
{% set native = 'm2w64-' if win else '' %}

package:
  name: r-tokenizers
  version: {{ version|replace("-", "_") }}

source:
  fn: tokenizers_{{ version }}.tar.gz
  url:
    - https://cran.r-project.org/src/contrib/tokenizers_{{ version }}.tar.gz
    - https://cran.r-project.org/src/contrib/Archive/tokenizers/tokenizers_{{ version }}.tar.gz
  sha256: 693e19e32605f4c66a51b1eb84258a973ac2fe1d2f919b28e66944721aab9ae1

build:
  number: 0
  skip: true  # [win32]

  rpaths:
    - lib/R/lib/
    - lib/

requirements:
  build:
    - r-base
    - r-rcpp >=0.12.3
    - r-snowballc >=0.5.1
    - r-stringi >=1.0.1
    - posix                # [win]
    - {{native}}toolchain  # [win]
    - gcc                  # [not win]

  run:
    - r-base
    - r-rcpp >=0.12.3
    - r-snowballc >=0.5.1
    - r-stringi >=1.0.1

test:
  commands:
    - $R -e "library('tokenizers')"  # [not win]
    - "\"%R%\" -e \"library('tokenizers')\""  # [win]

about:
  home: https://github.com/ropensci/tokenizers
  license: MIT
  summary: Convert natural language text into tokens. The tokenizers have a consistent interface
    and are compatible with Unicode, thanks to being built on the 'stringi' package.
    Includes tokenizers for shingled n-grams, skip n-grams, words, word stems, sentences,
    paragraphs, characters, lines, and regular expressions.
  license_family: MIT

extra:
  recipe-maintainers:
    - johanneskoester
    - bgruening
