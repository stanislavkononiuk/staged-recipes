# Test with forked repo and fix, temporary git source to be replaced later
{% set name = "pdpipe" %}
{% set version = "0.0.521" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  #url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
  #sha256: 38a751617e222a52afde1315148850c70ef1eee75e4475f4bba9829fe6b160f9
  url: https://github.com/Silun/pdpipe/archive/v{{ version }}.tar.gz
  sha256: f2d495e541b6eaa6fd2e0b52dc315dfa770fda9c1b170060f008922ebfc66f0a

build:
  noarch: python
  number: 0
  script: "{{ PYTHON }} -m pip install . -vv"

requirements:
  host:
    - python >=3.6,<=3.8
    - pip
  run:
    - python >=3.6,<=3.8
    - pandas >=0.18.0
    - sortedcontainers
    - strct
    - tqdm
    - skutil >=0.0.15
    - scikit-learn
    - nltk

test:
  imports:
    - pdpipe

about:
  home: https://pdpipe.github.io/pdpipe/
  license: MIT
  license_family: MIT
  license_file: LICENSE.txt
  summary: 'Easy pipelines for pandas.'
  doc_url: https://pdpipe.github.io/pdpipe/doc/pdpipe/
  dev_url: https://github.com/pdpipe/pdpipe

  description: |
    Ever written a preprocessing pipeline for pandas dataframes and had trouble serializing it for later depoloyment on a different machine? Ever needed fit-able preprocessing transformations, that have tunable paramaters that are inferred from training data, to be used later to transform input data? Ever struggled with preprocessing different types of data in the same pandas dataframe? Enter pdpipe, a simple framework for serializable, chainable and verbose pandas pipelines. Its intuitive API enables you to generate, using only a few lines, complex pandas processing pipelines that can easily be broken down or composed together, examined and debugged, and that adhere to scikit-learn's Transformer API. Stop writing the same preprocessing boilerplate code again and again!

extra:
  recipe-maintainers:
    - Silun
