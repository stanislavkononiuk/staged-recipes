{% set name = "syntok" %}
{% set version = "1.3.1" %}


package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz
  sha256: 4e10ed25e5cd131138fe75ae39917f6d70deab07da57726564f602daa2d5303e

build:
  number: 0
  noarch: python
  script: {{ PYTHON }} -m pip install . -vv

requirements:
  host:
    - pip
    - python =2.7|>=3.5
  run:
    - python =2.7|>=3.5
    - regex

test:
  imports:
    - syntok
  commands:
    - pip check
  requires:
    - pip

about:
  home: https://github.com/fnl/syntok
  summary: sentence segmentation and word tokenization toolkit
  description: |
    Syntok is the successor of an earlier, very similar tool, segtok, but has evolved
    significantly in terms of providing better segmentation and tokenization performance
    and throughput (syntok can segment documents at a rate of about 100k tokens per
    second without problems). For example, if a sentence terminal marker is not
    followed by a spacing character, segtok is unable to detect that as a terminal
    marker, while syntok has no problem segmenting that case (as it uses tokenization
    first, and does segmentation afterwards).
  license: MIT
  license_family: MIT
  license_file: LICENSE

extra:
  recipe-maintainers:
    - BastianZim
