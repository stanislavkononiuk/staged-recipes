{% set name = "alibi" %}
{% set version = "0.6.3" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

build:
  number: 0
  skip: true  # [py<37]
  script: {{ PYTHON }} -m pip install . -vv

source:
  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/alibi-{{ version }}.tar.gz
  sha256: 20131a369871b32bc7abfe1caa47131657abc0e41c7f5c8e0d2cc6105a816a96

requirements:
  host:
    - pip
    - python
  run:
    - python
    - attrs >=19.2.0,<22.0.0
    - dill >=0.3.0,<0.4.0
    - matplotlib-base >=3.0.0,<4.0.0
    - numpy >=1.16.2,<2.0.0
    - pandas >=0.23.3,<2.0.0
    - pillow >=5.4.1,<9.0
    - requests >=2.21.0,<3.0.0
    - scikit-image >=0.14.2,!=0.17.1,<0.19
    - scikit-learn >=0.20.2,<1.1.0
    - scipy >=1.1.0,<2.0.0
    - spacy >=2.0.0,<4.0.0
    - tensorflow >=2.0.0,!=2.6.0,!=2.6.1,<2.8.0
    - tqdm >=4.28.1,<5.0.0
    - transformers >=4.7.0,<5.0.0
    - typing-extensions >=3.7.2  # [py<38]

test:
  imports:
    - alibi
  commands:
    - pip check
  requires:
    - pip

about:
  home: https://github.com/SeldonIO/alibi
  summary: Algorithms for monitoring and explaining machine learning models
  license: Apache-2.0
  license_file: LICENSE
  description: |
    [Alibi](https://docs.seldon.io/projects/alibi) is an open source Python 
    library aimed at machine learning model 
    inspection and interpretation. The focus of the library is to provide 
    high-quality implementations of black-box, white-box, local and global 
    explanation methods for classification and regression models.

    - [Documentation](https://docs.seldon.io/projects/alibi/en/latest/)

    If you're interested in outlier detection, concept drift or adversarial 
    instance detection, check out our sister project 
    [alibi-detect](https://github.com/SeldonIO/alibi-detect).

    PyPI: [https://pypi.org/project/alibi/](https://pypi.org/project/alibi/)

  doc_url: https://docs.seldon.io/projects/alibi/en/latest/
  dev_url: https://github.com/SeldonIO/alibi

extra:
  recipe-maintainers:
    - sugatoray
